{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>session</th>\n",
       "      <th>method</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>n_annotators</th>\n",
       "      <th>agreement</th>\n",
       "      <th>path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>neu</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>Fine.\\n</td>\n",
       "      <td>2.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>fru</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>[BREATHING]\\n</td>\n",
       "      <td>1.502438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>neu</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>That's not your flashlight.\\n</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>ang</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>You keep saying my flashlight like it's just ...</td>\n",
       "      <td>2.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>ang</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>How's that supposed to make me feel?\\n</td>\n",
       "      <td>1.819937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  session  method gender emotion  n_annotators  agreement  \\\n",
       "0           0        1  script      F     neu             3          3   \n",
       "1           1        1  script      F     fru             3          2   \n",
       "2           2        1  script      F     neu             3          2   \n",
       "3           3        1  script      F     ang             3          2   \n",
       "4           4        1  script      F     ang             3          2   \n",
       "\n",
       "                                                path  \\\n",
       "0  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
       "1  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
       "2  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
       "3  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
       "4  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
       "\n",
       "                                          transcript  duration  \n",
       "0                                            Fine.\\n  2.070000  \n",
       "1                                      [BREATHING]\\n  1.502438  \n",
       "2                      That's not your flashlight.\\n  2.180000  \n",
       "3   You keep saying my flashlight like it's just ...  2.970000  \n",
       "4             How's that supposed to make me feel?\\n  1.819937  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data  =  pd.read_csv('/Users/adham/Desktop/EMO_REC/Iemocap_clean_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/adham/Desktop/EMO_REC/IEMOCAP_full_release/Sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Session1/sentences/wav/Ses01F_script02_1/Ses01F_script02_1_F000.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_speech = pd.DataFrame()\n",
    "data_speech['path'] = data['path']\n",
    "data_speech['emotion'] = data['emotion']\n",
    "data_speech['duration'] = data['duration']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Session1/sentences/wav/Ses01F_script02_1/Ses01F_script02_1_F000.wav'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_speech)\n",
    "data_speech.head()\n",
    "data_speech['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "import torchaudio\n",
    "\n",
    "# # Load the pre-trained model and processor\n",
    "model = Wav2Vec2Model.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "\n",
    "# # Load your audio file as a PyTorch tensor\n",
    "embeddingsList=[]\n",
    "for i in range(len(data_speech)):\n",
    "\n",
    "   audio, sample_rate = torchaudio.load(data_speech['path'][i])\n",
    "   #print(audio.shape)\n",
    "   # # Preprocess the audio data\n",
    "   input_values = processor(audio, sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "   \n",
    "   # Reshape input tensor to remove extra dimension\n",
    "   input_values = input_values.squeeze(0)\n",
    "\n",
    "   # # # Generate embeddings\n",
    "   with torch.no_grad():\n",
    "      embeddings = model(input_values).last_hidden_state.mean(dim=1)\n",
    "   #print(embeddings.shape)\n",
    "   embeddingsList.append(embeddings)\n",
    "   # # The embeddings variable now contains the embeddings for your audio data\n",
    "   #print(embeddings.shape)\n",
    "#data_speech['embeddings'] = embeddingsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adham/Desktop/EMO_REC/IEMOCAP_full_release/Sessions'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.to_csv(\"IemoCap_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_speech = pd.read_csv('IemoCap_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.to_csv(\"IemoCap_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>duration</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>neu</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>tensor([[-4.2297e-02,  1.1443e-02,  1.4771e-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>fru</td>\n",
       "      <td>1.502438</td>\n",
       "      <td>tensor([[-5.7967e-02,  2.9345e-02, -6.6958e-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>neu</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>tensor([[ 6.3062e-03, -6.7126e-03, -1.0135e-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>ang</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>tensor([[-3.1424e-03, -2.9699e-02, -1.4094e-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n",
       "      <td>ang</td>\n",
       "      <td>1.819937</td>\n",
       "      <td>tensor([[-1.9856e-02, -2.3386e-03, -5.5584e-02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path emotion  \\\n",
       "0           0  Session1/sentences/wav/Ses01F_script02_1/Ses01...     neu   \n",
       "1           1  Session1/sentences/wav/Ses01F_script02_1/Ses01...     fru   \n",
       "2           2  Session1/sentences/wav/Ses01F_script02_1/Ses01...     neu   \n",
       "3           3  Session1/sentences/wav/Ses01F_script02_1/Ses01...     ang   \n",
       "4           4  Session1/sentences/wav/Ses01F_script02_1/Ses01...     ang   \n",
       "\n",
       "   duration                                         embeddings  \n",
       "0  2.070000  tensor([[-4.2297e-02,  1.1443e-02,  1.4771e-03...  \n",
       "1  1.502438  tensor([[-5.7967e-02,  2.9345e-02, -6.6958e-02...  \n",
       "2  2.180000  tensor([[ 6.3062e-03, -6.7126e-03, -1.0135e-01...  \n",
       "3  2.970000  tensor([[-3.1424e-03, -2.9699e-02, -1.4094e-01...  \n",
       "4  1.819937  tensor([[-1.9856e-02, -2.3386e-03, -5.5584e-02...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# read the CSV file\n",
    "\n",
    "# extract the string representation of the tensor from the column\n",
    "embeddings_tensor=[]\n",
    "for i in range(len(data_speech)):\n",
    "    tensor_string = data_speech['embeddings'][i]  # assuming there is only one row in the dataframe\n",
    "    #print(tensor_string[9:-3])\n",
    "    # convert the string representation to a numpy array\n",
    "    tensor_array = np.fromstring(tensor_string[9:-3], sep=',')\n",
    "\n",
    "    # convert the numpy array to a PyTorch tensor\n",
    "    tensor = torch.from_numpy(tensor_array)\n",
    "    embeddings_tensor.append(tensor)\n",
    "    # print the tensor\n",
    "    #print(\"tensor = \",tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_tensor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# save the list of tensors to a file\n",
    "torch.save(embeddings_tensor, 'embeddings_list.pt')\n",
    "\n",
    "# # load the saved list of tensors\n",
    "embeddings_tensor = torch.load('embeddings_list.pt')\n",
    "\n",
    "# # print the loaded tensor list\n",
    "# print(loaded_tensor_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6785,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speech['embeddings'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = data_speech['emotion']\n",
    "# Initialize a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the labels\n",
    "le.fit(labels)\n",
    "\n",
    "# Transform the labels to categorical numbers\n",
    "label_nums = le.transform(labels)\n",
    "\n",
    "print(label_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data_speech)):\n\u001b[1;32m      2\u001b[0m    embeddings \u001b[39m=\u001b[39m data_speech[\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[0;32m----> 3\u001b[0m    t_flat \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m    data_speech[\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m t_flat\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_speech)):\n",
    "   embeddings = data_speech['embeddings'][i]\n",
    "   t_flat = embeddings.view(-1)\n",
    "   data_speech['embeddings'][i] = t_flat\n",
    "#t_flat = embeddings[0].view(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embeddings_tensor)\n",
    "\n",
    "# convert the Series object to a PyTorch tensor\n",
    "#t = torch.tensor(data_speech['embeddings'].values.tolist())\n",
    "\n",
    "tensor_stack = torch.stack(embeddings_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor_stack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
